<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Tushar Kumar Tiwari | MLOps Engineer</title>
  <link rel="stylesheet" href="styles/main.css">
</head>
<body>

  <section class="hero">
    <h1>Tushar Kumar Tiwari</h1>
    <h2>MLOps Engineer | Cloud & Automation Enthusiast</h2>
    <p>Building reliable, reproducible, and cost-aware ML systems</p>
  </section>

  <section class="card">
    <h3>About Me</h3>
    <p>
      Infrastructure Support Engineer with hands-on experience in cloud platforms,
      automation, monitoring, and production support. Currently transitioning into
      MLOps by building end-to-end machine learning pipelines with CI/CD, containerization,
      and deployment using free and open-source tools.
    </p>
  </section>

  <section class="card">
    <h3>Core Skills</h3>
    <ul>
      <li><b>MLOps:</b> Model lifecycle management, CI/CD for ML, reproducibility</li>
      <li><b>ML:</b> scikit-learn, model evaluation, inference pipelines</li>
      <li><b>LLMOps:</b> Prompt versioning, inference pipelines, cost-aware design</li>
      <li><b>Cloud & DevOps:</b> GitHub Actions, Docker, Linux, Bash</li>
      <li><b>Monitoring:</b> Logs, metrics, latency tracking (conceptual + hands-on)</li>
    </ul>
  </section>

  <section class="card">
    <h3>Certifications</h3>
    <ul>
      <li>Microsoft Azure AZ-900</li>
    </ul>
  </section>

  <section class="card">
    <h3>Projects</h3>

    <h4>1. End-to-End MLOps Pipeline – Iris Dataset</h4>
    <p>
      Built a complete MLOps pipeline using the Iris dataset to demonstrate
      model training, versioning, CI/CD automation, and containerized inference
      using only free tools.
    </p>
    <ul>
      <li>Automated training & validation using GitHub Actions</li>
      <li>Dockerized inference service</li>
      <li>CI/CD-driven deployments</li>
      <li>Focus on reproducibility and reliability</li>
    </ul>

    <h4>2. Computer Vision MLOps Pipeline – YOLO</h4>
    <p>
      Designed a lightweight deployment-ready MLOps workflow for object detection
      using a pre-trained YOLO model, focusing on inference pipelines and monitoring concepts.
    </p>
    <ul>
      <li>Pre-trained model integration</li>
      <li>Docker-based inference service</li>
      <li>CI pipeline for build and validation</li>
      <li>Latency and logging considerations</li>
    </ul>

    <h4>3. LLM Inference & Prompt Management Pipeline</h4>
    <p>
      Implemented an LLM inference workflow using open-source models with emphasis on
      prompt versioning, cost awareness, and free deployment strategies.
    </p>
    <ul>
      <li>Prompt lifecycle management</li>
      <li>Inference abstraction</li>
      <li>CI for prompt changes</li>
      <li>No paid APIs or cloud services</li>
    </ul>

  </section>

  <section class="card">
    <h3>Contact</h3>
    <p>
      GitHub: <a href="https://github.com/YOUR_GITHUB" target="_blank">github.com/YOUR_GITHUB</a>
    </p>
  </section>

  <footer>
    <p>© 2025 — Built with HTML, CSS & GitHub Actions</p>
  </footer>


</body>
</html>
