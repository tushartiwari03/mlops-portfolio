<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Tushar Kumar Tiwari | MLOps Engineer</title>
  <link rel="stylesheet" href="styles/main.css">
</head>
<body>

  <section class="hero">
    <h1>Tushar Kumar Tiwari</h1>
    <h2>MLOps Engineer | Cloud & Automation Enthusiast</h2>
    <p>Building reliable, reproducible, and cost-aware ML systems</p>
  </section>

  <section class="card">
    <h3>About Me</h3>
    <p>
      Infrastructure Support Engineer with hands-on experience in cloud platforms,
      automation, monitoring, and production support. Currently transitioning into
      MLOps by building end-to-end machine learning pipelines with CI/CD, containerization,
      and deployment using free and open-source tools.
    </p>
  </section>

  <section class="card">
    <h3>Core Skills</h3>
    <ul>
      <li><b>MLOps:</b> Model lifecycle management, CI/CD for ML, reproducibility</li>
      <li><b>ML:</b> scikit-learn, model evaluation, inference pipelines</li>
      <li><b>LLMOps:</b> Prompt versioning, inference pipelines, cost-aware design</li>
      <li><b>Cloud & DevOps:</b> GitHub Actions, Docker, Linux, Bash</li>
      <li><b>Monitoring:</b> Logs, metrics, latency tracking (conceptual + hands-on)</li>
    </ul>
  </section>

  <section class="card">
    <h3>Certifications</h3>
    <ul>
      <li>Microsoft Azure AZ-900</li>
    </ul>
  </section>

  <section class="card">
    <h3>Projects</h3>

    <h4>1. Config-Driven MLOps Pipeline – Iris Dataset</h4>
    <p>
      Designed and implemented an end-to-end MLOps pipeline where multiple machine
      learning models can be trained, validated, and packaged for inference using
      a single reusable pipeline.
    </p>

     <p>
     The pipeline is configuration-driven, allowing data scientists to train
     different models by modifying a YAML file without changing code.
     </p>

     <ul>
        <li>Single pipeline supports multiple ML models (Logistic Regression, Random Forest, SVM)</li>
        <li>Quality gates enforce minimum model accuracy during CI</li>
   	<li>Automated training and testing using GitHub Actions</li>
  	<li>Model artifacts are versioned and ready for inference</li>
  	<li>Fully implemented using free and open-source tools</li>
     </ul>

	<p>
	<b>MLOps Concepts:</b> CI/CD for ML, model validation gates, config-driven pipelines,
	reproducibility, automation
	</p>

	<p>
	<b>Tech Stack:</b> Python, scikit-learn, GitHub Actions, YAML, Docker-ready design
	</p>

	<p>
	<b>Repository:</b>
	<a href="https://github.com/tushartiwari03/iris-mlops-pipeline" target="_blank">
	github.com/tushartiwari03/iris-mlops-pipeline
	</a>
	<p>
  	<img src="https://github.com/tushartiwari03/iris-mlops-pipeline/actions/workflows/ci.yml/badge.svg"
       	alt="Iris MLOps CI Status">
	</p>
	
	</p>
    <h4>2. Computer Vision MLOps Pipeline – YOLO</h4>
    <p>
      Designed a lightweight deployment-ready MLOps workflow for object detection
      using a pre-trained YOLO model, focusing on inference pipelines and monitoring concepts.
    </p>
    <ul>
      <li>Pre-trained model integration</li>
      <li>Docker-based inference service</li>
      <li>CI pipeline for build and validation</li>
      <li>Latency and logging considerations</li>
    </ul>

    <h4>3. LLM Inference & Prompt Management Pipeline</h4>
    <p>
      Implemented an LLM inference workflow using open-source models with emphasis on
      prompt versioning, cost awareness, and free deployment strategies.
    </p>
    <ul>
      <li>Prompt lifecycle management</li>
      <li>Inference abstraction</li>
      <li>CI for prompt changes</li>
      <li>No paid APIs or cloud services</li>
    </ul>

  </section>

  <section class="card">
    <h3>Contact</h3>
    <p>
      GitHub: <a href="https://github.com/tushartiwari03" target="_blank">github.com/tushartiwari03</a>
    </p>
  </section>

  <footer>
    <p>© 2025 — Built with HTML, CSS & GitHub Actions</p>
  </footer>


</body>
</html>
